개인적인 생각

팀원들 역할
선정이유
==== 큰 의의를 안둬도 될 것 같아요 ==== 



1. 전처리

	19개 피처

범주형이 5개  gender, marital, education, income, card

		Encoding 했었죠 수치형으로 바꾸고
		NaN
		대표값 결측치 처리
		

수치형이 14개 

		히트맵을 그려서 각 독립변수 간의 상관성 확인


이래서 상관성이 높았다
Why ? 같은 공식에서 나왔기 때문에 <==
거기서 어어 ? 이상한데

사실 도메인이 비슷하니까 상관계수가 높을 수 밖에 없던거임
저거 두개가 뿌리가 같은 도메인이 아니니까
중요하게 생각하는데
두개가 상관계수는 높게 나올 수 있지만
모델링을 진행하는 '사람' 선택을 할 수 잇죠
아 얘네 두개는 상관계수는 높게 나왔지만
사실 상관이 없는 독립변수기 때문에
그냥 써도 된다.
왜? 높게 나왔냐 저거 두개가 단순하게 숫자의 배열이잖아요
아무런 상관이 없는데
그냥 단순 숫자 배열만 놓고 보니까 상관성이 높게 나왔던거죠
우연적으로 그렇게 볼 수 있죠

아니죠 그거대로 해석을 하는게
상관성이 왜 높은지를 봐야해요
데이터를 보니까
아니 사실 만개짜리 데이터긴 한데
실제로 가능한 경우의수는
고작해야 250가지인데

나이 50개의 숫자고
Month 5개인데 
250개 
분류를 하는거니까요
250개중에 만개를 분류
거까지 들어가기전에
우리가 서로 알아야할게있어요
corr heatmap이 코드가
정확히
어떤 방식으로
상관성을
나타내는지를
알아야해요
수치형-수치형 상관성을 보는거에요
지워야 머신러닝 할 때 과적합이 일어나지 않으니까요
무지성으로 무조건 지운다는게 아니잖아요
0.8

나올 수 있다. 그렇죠 그렇긴한데
그렇다면

히트맵은 전혀 의미가 없다. (맞죠?)
머신러닝을 진행 할 때
각각의 도메인에 관한 지식을
완벽하게 숙지를 무조건 한 후에 해야겠네요
수치적으로 나타내는게 불가능하니까

제가 잠깐 물어보고 올게요
그니까 
저는 0.79숫자가
우연적으로 나올 수 있다고 봐요
물어보고 올게요]





처음에 진행 할 때

Heatmap을 그려서 

수치형 독립변수끼리의 상관성을 본 후에

상관성이 높으면 왜 높은지를 분석을 해서

정말 같은 도메인에서 파생된 변수라면

모델링 전에 한 개만 남기고 Drop을 시킨다.

== 여기서 == 희진님이 No, 성준님이 No

했지요

서로 다른 이유였지만 아무튼 No를 무조건 아니라고

결론적으로는

히트맵 상관성이 높다의 구체적 기준이 있음
0.85 이상 이면 높다고 본데요.

같은 도메인에서 파생됐는데
상관성이 낮게 나오는 경우는 아예 없다.

Age , Month
상관성이 높지만
우리가 알고있죠 도메인 지식을 이거 두개가 독립적이라는걸
그래서 히트맵상 상관성이 높게는 나오지만
우리가 갖고있는 도메인관한 지식으로 인해서
두 개다 쓴다 <== 동의를 했었고

희진님은

수치만 다를 뿐 제 말이 맞았습니다.
지울 때

우리가 했던 방향이
우리가 제대로 했죠
히트맵을 보면서 도메인지식을 활용을 했죠
두개가 동시 다발적으로 일어났죠

결과는 똑같에요

상관성이 있는 피쳐를 드랍시켰다 적절하게.

우리의 과정은
동시에 했죠
하나를 보고 다른 하나를 한게 아니라
동시에 했죠
사고를.

우리가 선택한 상관성이 높다의 기준 (0.3) 
이거는 틀렸다.

0.85이상이 높은거다.

강사님 왈 : 본인은 모델링을 진행 할 때

상관성이 높게 나오면 그게 독립적이었든 아니었든 드랍은 시킨다.

Month on book, Age 상관성이 높다곤 할 순 없죠 0.85 이상일때 라고 했어요
근데 

모델링 하는 사람들이 판단을 한데요.

"사람이 어떻게 하느냐에 달렸데요"

우리가 한 방법은 맞았어요

둘중 하나지우는건 맞아요.

그리고

Credit Limit = Avg_total + Avg_open 


open to buy = credit limit 동일한 도메인이라서

여기서 둘중만 쓰는게 맞는 과정이었어요
결론적으로는 우리는 잘 했다.
과정은 틀렸을지라도
이연상관계수를 쓰는것도 맞데요 상관성이 높은걸 남기고 낮은걸 드랍시켰다.
이때 만약에
모델링 결과가
0.5 정도가 나오면
이거를 더 나은 모델링을 찾아야하니까
이 때 하나의 방법이 되는거죠
근데 우리의 모델링은 상당히 높은 그 뭐랄까,, 예 잘됐다.

선택을 할 수 있데요
저게 필수적인 과정은 아니래요 도메인 어느정도 있다는 전제하에는
변수 두개가 미리 상관성이 있다는걸 알고 있으니까
모델링을 진행하면서
둘중 하나를 번갈아가면서 쓰면서
더 나은 모델을 찾는거래요.

Credit Limit 일반적으로는
할 때 히트맵을 봐야하는데

제가 잘못보고있었어요,,


같은 도메인에서 나오지 않은 변수들도

우연하게 

상관성이 높게 나올 수 있다.


팀원들은

같은 도메인에서 나오지 않은 변수가 

상관성이 높게 나온거는 말이 안된다


레코드 자체가 하나의 집합 전혀 없을 수 가 없다.


우연하게 높게 나왔던 안나왔던 
삭제는 무조건 한다.
분류에서는 특히 상관성이 높으면 하나로 읽게 된다

도메인 적으로 전혀 모르는 데이터인데 
상관성이 높게 나왔다면 지워야한다.

결국 선택의 문제 
상관성이 높게 나오면

만약에 Drop순서를 말 할 때

저는 히트맵을 보고 상관성을 확인 한 후에
범주형 (타겟) 수치형(변수)
수치형을 Drop을 시켜야 하는데
수치형끼리 상관성이 높은 것 들 중에서
	타겟이랑 변수간의 상관계수가 높은걸 
	pointbiserialr (이연상관계수) 
팀원들 의견이 나온게

제일 중요한 전제가 히트맵은 쓸모가 없다.
왜냐면 도메인관한 지식을 무조건 안 후에
머신러닝을 진행해야 한다.
도메인 관한 지식을 아니까
히트맵을 볼 이유가 전무하다.

도메인을 아니까

저거 세 개가 같은 공식에서 나온거라서.

Credit Limit = Total_Revolving_Bal + Avg_Open_to_buy

다른 변수들 대비 상관성이 높다고 판단을 해서

저거 세 개중 한 개의 변수만 쓰기로 한거에요.

아,, 제가 완전 잘못 보고있었네요,,

Avg_Utilization_Ratio = Total_Revolving_Bal / Credit_Limit

상관성이 높다라는건

0.85~0.9 이상이 될 때 제거를 한다.

두 독립변수가 상관성이 높지만 필요변수로 판단.
왜 상관선이 높을까 라고 물어보면 

답변이,,? 있을까요,,
코드가 어떻게 작동을 하는지 간략하게 알 수

각각 상관성을 확인 한 후에 

의견이 총 2개

제 의견 : 히트맵을 보고 상관성이 높으면 왜 높은지를 확인을 해야한다.

집의 크기를 놓고 볼 때 단위가 다른 데이터가 두 개가 들어와있다고 하면

상관성이 있던 없던 하나만 써야한다.

팀원들 의견 : 

내가 직접수집을 하면,, 어딘가에서 내가 발생시켜서 
의미를 아는게 아니라

어딘가에 있는 데이터를 끄집어 온거니까

완벽하게 알지 못하니까

그래서 상관성을 봐야한다.

결국 두 개의 의견이 합쳐져야 하는거네요,,

집평수 
다른 두개의 단위가 들어왔을 때
상관성이 안나타나는 경우가 있나요?

무시를 하면 안되는데

두개 같이 동시다발적으로
히트맵을 보면서 도메인관한 배경들을 동시에 생각해야한다.

우연의 일치로 나오는 경우는 없습니다.
히트맵은 무조건 봐야되구요

히트맵을 보고 상관성을 확인 한 후에 도메인 지식을 겯들여서이제 확인을해야하는,,


		
		타겟 Attrition_Flag 상관관계 함수
		pointbiserialr (이연상관계수) [수치형 - 범주형]
		를 통해 correlation 을 보고 Drop 결정


		로그변환 (Credit Limit)
		표준화 스케일링		

우리가 했던게 맞다
다른 의견을 통합시키는 과정이 필요할 뿐.

2. 모델링
	
	모델링 정리라는게 혹시 어떤건가요
	
	lr, [xgb, lgb] (dt를 포함하고 있지만 다른 모델링이죠)
	다른 모델링 randomforest, decisiontree, Knieghbors, SVC
	smote <== 이거를 몰라서 label 1,0 15% , 85% (upsampling)
	성능이 더 좋아지지 않았었나요

	임계점하는거를
	 7개의 모델

	1. 전처리 한거로 먼저 진행을해보고/ 성능 안좋은 모델을 모아서 앙상블
	2. 하이퍼파라미터로 피처들을 바꾸고 다시 모델링 진행/ 성능 안좋은 모델을 모아서 앙상블
	3. smote 해서 모델링 진행/ 성능 안좋은 모델을 모아서 앙상블
	4. 이 중에서 제일 괜찮은걸 Trade off/ 성능 안좋은 모델을 모아서 앙상블
	임계점 값 변경하고 (Trade/off)
	smote진행후에 모델링 진행

해놓은거는 lr xgb lgb = 기본모델링, trade off
			+ 하이퍼파라미터, 업샘플링

희진님이 randomforest, decisiontree, Knieghbors, SVC = 기본샘플링, 업샘플링
			+ 하이퍼파라미터, trade off

성능 안좋은거 모아서 앙상블을 진행해보자
발표가 내일맞나요? 
내일 2시? 흠,,
혹시 다들 이거 코드 진행 가능 한가요

저는 저거 희진님이 올려놓은 코드로 진행 할 수 있거든요//
7개를 다하면 혼자하면 시간이 좀 더 필요할 것 같아서

28개의 종류가 있는데 8개를 마무리했으니까

20개가 남았어요 === 개념이 없다는게 아까 했던것처럼 정말 개념적인
코드 오류가 나서 잘 안되는거에요
해봤는데 확실하지가 않은거에요

제가 해놨던거에서 업샘플링

전처리 = smote
학습 테스트 
lr_clf 
학습/테스트

x_train, y_train
x_train_smote, y_train_smote

두개로 다시 진행
다시 성능 측정

roc-auc <= 이게 왜 안되는지 아는데
이게뭔진 몰라요
v3에 제가 다 정리해놨으니까
거기다가 희진님이를 한거를
같이보면서 추가를 하면 될 것 같아요 오후에

제가 화면공유하면서 후딱후딱 복붙 바꾸고
소문자로 다 바꿨어요
통합본 폴더 =

해놓은거는 모델명만 바꾸면 되니까요

2시 넉넉하게 

못한건
하이퍼파라미터, 앙상블
	



